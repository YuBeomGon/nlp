{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaModel\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import torch.nn as nn\n",
    "\n",
    "from util import *\n",
    "from losses import LabelSmoothingCrossEntropy\n",
    "from augment import *\n",
    "\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "# from torch_model import SupConRobertaNet, SupConMultiRobertaNet\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from torch_model import MLPRobertaNet, CNNRobertaNet, SIMRobertaNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.SE_index = [ i for i, c in enumerate(df.columns) if \"SE\" in c][0]\n",
    "        self.label_index = [ i for i, c in enumerate(df.columns) if \"label_id\" in c][0]\n",
    "        self.Num_class = len(df[df.columns[self.label_index]].value_counts())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, self.SE_index]\n",
    "        label = self.df.iloc[idx, self.label_index]\n",
    "        return text, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(4674, 14)\n",
      "(813, 14)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('files/train3.csv')\n",
    "test_df = pd.read_csv('files/test3.csv')\n",
    "Num_Label = len(train_df.label_id.value_counts())\n",
    "print(Num_Label)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_info_dict = {16: ' 치주 질환 / 치주염 (젖니 유전자 좌로 유래하는 것 포함)치아 및 구강 질환 ',\n",
    " 12: ' 세균성 장염  소화기 질환 ',\n",
    " 15: ' 췌장염  간 · 담도계 및 췌장 질환',\n",
    " 13: ' 유선 종양 / 유방 종괴  생식기 질환 ',\n",
    " 14: ' 자궁 축농증  생식기 질환 ',\n",
    " 11: ' 판막증 (의심 포함한 심장 잡음 + 심부전 증후 자) 순환기 질환 ',\n",
    " 7: ' 소화관 이물 / 섭취  소화기 질환 ',\n",
    " 10: ' 만성 신장 질환 (신부전 포함)  비뇨기과 질환 ',\n",
    " 3: ' 구토 / 설사 / 혈변 (원인 미정)  소화기 질환 ',\n",
    " 5: ' 방광염  비뇨기과 질환 ',\n",
    " 9: '슬개골 (아) 탈구 근육 골격 질환 ',\n",
    " 1: ' 경련 발작 (원인 미정)  신경 질환 ',\n",
    " 2: ' 고양이 하부 요로 질환 FUS · FLUTD  비뇨기과 질환 ',\n",
    " 17: ' 폐렴  호흡기 질환 ',\n",
    " 0: ' 간 / 담도 / 췌장의 종양  간 · 담도계 및 췌장 질환',\n",
    " 4: ' 당뇨병 내분비 질환 ',\n",
    " 8: ' 수막염 / 수막 뇌염 / 뇌염  신경 질환 ',\n",
    " 6: ' 빈혈 (면역 개입 용혈성) IMHA 혈액 및 조혈기의 질환 '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "# pretrained_path = './pretrained_without_wiki'\n",
    "pretrained_path = './pretrained_without_wiki/'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(pretrained_path, do_lower_case=False)\n",
    "# donwstream_class_num = task_label_dict['diags_id']\n",
    "# model = MLPRobertaNet(path=pretrained_path, \n",
    "model = SIMRobertaNet(path=pretrained_path,                       \n",
    "                              embedding_dim=768,\n",
    "                              max_seq_length=MAX_SEQ_LEN, \n",
    "                              num_class=Num_Label)\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reset_parameters(model):\n",
    "#     for p in model.parameters():\n",
    "#         if p.dim() > 1:\n",
    "#             nn.init.xavier_uniform_(p)\n",
    "            \n",
    "# reset_parameters(model)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters() :\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor_dict = {}\n",
    "device = torch.device(\"cpu\")\n",
    "for label, text in label_info_dict.items():\n",
    "#     print(text)\n",
    "    encoded_list = [tokenizer.encode(t, add_special_tokens=True, max_length=512, truncation=True) for t in [text]]\n",
    "#     print(encoded_list)\n",
    "    padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "    sample = torch.tensor(padded_list)\n",
    "    sample = sample.to(device)\n",
    "    outputs = model(sample=sample, isLabel=True)\n",
    "    label_tensor_dict[label] = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x) :\n",
    "    return x[0]\n",
    "sorted_label_tensor_dict = sorted(label_tensor_dict.items(), key=f1, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_label_tensor_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.empty([1,768])\n",
    "for label, narray in sorted_label_tensor_dict:\n",
    "#     print(label)\n",
    "    if label == 0 :\n",
    "        label_array = narray\n",
    "#         print(label_array)\n",
    "    else :\n",
    "        label_array = np.concatenate([label_array, narray], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 18])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_tensor = torch.from_numpy(label_array.reshape(768, -1))\n",
    "label_tensor = torch.normal(0, 0.1, size=(768,18))\n",
    "label_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_tensor = F.normalize(label_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_tensor() :\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    label_tensor_dict = {}\n",
    "    for label, text in label_info_dict.items():\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True, max_length=512, truncation=True) for t in [text]]\n",
    "    #     print(encoded_list)\n",
    "        padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample = sample.to(device)\n",
    "        outputs = model(sample=sample, isLabel=True)\n",
    "#         label_tensor_dict[label] = outputs.detach().numpy()   \n",
    "        label_tensor_dict[label] = outputs.detach()\n",
    "        \n",
    "    sorted_label_tensor_dict = sorted(label_tensor_dict.items(), key=f1, reverse=False)\n",
    "        \n",
    "#     label_array = np.empty([1,768])\n",
    "    label_array = torch.empty([1,768])\n",
    "    for label, narray in sorted_label_tensor_dict:\n",
    "    #     print(label)\n",
    "        if label == 0 :\n",
    "            label_array = narray\n",
    "    #         print(label_array)\n",
    "        else :\n",
    "#             label_array = np.concatenate([label_array, narray], axis=0)  \n",
    "            label_array = torch.cat([label_array, narray], dim=0) \n",
    "#     label_tensor = torch.from_numpy(label_array.reshape(768, -1))\n",
    "    label_tensor = label_array.reshape(768, -1)\n",
    "    label_tensor.size()\n",
    "    # label_tensor = F.normalize(label_tensor, dim=0)\n",
    "    return label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "label_tensor = label_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embeddings.word_embeddings.weight\n",
      "torch.Size([40000, 768])\n",
      "encoder.embeddings.position_embeddings.weight\n",
      "torch.Size([514, 768])\n",
      "encoder.embeddings.token_type_embeddings.weight\n",
      "torch.Size([1, 768])\n",
      "encoder.embeddings.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.embeddings.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.0.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.0.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.0.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.0.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.0.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.0.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.0.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.1.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.1.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.1.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.1.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.1.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.1.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.1.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.2.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.2.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.2.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.2.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.2.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.2.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.2.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.3.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.3.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.3.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.3.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.3.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.3.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.3.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.4.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.4.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.4.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.4.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.4.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.4.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.4.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.5.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.5.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.5.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.encoder.layer.5.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "encoder.encoder.layer.5.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "encoder.encoder.layer.5.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "encoder.encoder.layer.5.output.dense.bias\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "encoder.pooler.dense.weight\n",
      "torch.Size([768, 768])\n",
      "encoder.pooler.dense.bias\n",
      "torch.Size([768])\n",
      "fc.weight\n",
      "torch.Size([18, 768])\n",
      "fc.bias\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "for param, state in zip(model.parameters(), model.state_dict()) :\n",
    "    print(state)\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PetDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.00008)\n",
    "scheduler = lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer, lr_lambda=lambda epoch: 1 / ((epoch/4) + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(test_df, label_tensor) :\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     model.to(device)       \n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = PetDataset(test_df)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for text, label in test_loader:\n",
    "        #   encoded_list = [tokenizer.encode(t, add_special_token=True) for t in text]\n",
    "        encoded_list = [tokenizer.encode(t, max_length=512, truncation=True) for t in text]\n",
    "        padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        label = torch.tensor(label)\n",
    "        outputs = model(sample=sample, isLabel=False)\n",
    "        outputs = torch.matmul(outputs, label_tensor)\n",
    "#         outputs = torch.transpose(outputs, 1, 2)\n",
    "#         outputs = nn.AdaptiveMaxPool1d(1)(outputs)\n",
    "#         outputs = torch.squeeze(outputs)        \n",
    "        logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(label)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(label)\n",
    "\n",
    "    print('Test accuracy: ', total_correct / total_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0][100/585]\tloss 2.75637\n",
      "Train: [0][200/585]\tloss 2.74534\n",
      "Train: [0][300/585]\tloss 2.72913\n",
      "Train: [0][400/585]\tloss 2.61841\n",
      "Train: [0][500/585]\tloss 2.44493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/beomgon2/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5990159901599016\n",
      "***********************************\n",
      "Train: [1][100/585]\tloss 1.29158\n",
      "Train: [1][200/585]\tloss 1.27547\n",
      "Train: [1][300/585]\tloss 1.22379\n",
      "Train: [1][400/585]\tloss 1.20242\n",
      "Train: [1][500/585]\tloss 1.18251\n",
      "Test accuracy:  0.6371463714637147\n",
      "***********************************\n",
      "Train: [2][100/585]\tloss 0.83387\n",
      "Train: [2][200/585]\tloss 0.83700\n",
      "Train: [2][300/585]\tloss 0.82515\n",
      "Train: [2][400/585]\tloss 0.81222\n",
      "Train: [2][500/585]\tloss 0.80077\n",
      "Test accuracy:  0.6555965559655597\n",
      "***********************************\n",
      "Train: [3][100/585]\tloss 0.60680\n",
      "Train: [3][200/585]\tloss 0.57544\n",
      "Train: [3][300/585]\tloss 0.56977\n",
      "Train: [3][400/585]\tloss 0.56172\n",
      "Train: [3][500/585]\tloss 0.56131\n",
      "Test accuracy:  0.6875768757687577\n",
      "***********************************\n",
      "Train: [4][100/585]\tloss 0.37472\n",
      "Train: [4][200/585]\tloss 0.36471\n",
      "Train: [4][300/585]\tloss 0.36664\n",
      "Train: [4][400/585]\tloss 0.36864\n",
      "Train: [4][500/585]\tloss 0.36696\n",
      "Test accuracy:  0.6642066420664207\n",
      "***********************************\n",
      "Train: [5][100/585]\tloss 0.26796\n",
      "Train: [5][200/585]\tloss 0.27398\n",
      "Train: [5][300/585]\tloss 0.26121\n",
      "Train: [5][400/585]\tloss 0.24492\n",
      "Train: [5][500/585]\tloss 0.23659\n",
      "Test accuracy:  0.6678966789667896\n",
      "***********************************\n",
      "Train: [6][100/585]\tloss 0.13269\n",
      "Train: [6][200/585]\tloss 0.13689\n",
      "Train: [6][300/585]\tloss 0.13836\n",
      "Train: [6][400/585]\tloss 0.13513\n",
      "Train: [6][500/585]\tloss 0.12928\n",
      "Test accuracy:  0.6678966789667896\n",
      "***********************************\n",
      "Train: [7][100/585]\tloss 0.07619\n",
      "Train: [7][200/585]\tloss 0.07269\n",
      "Train: [7][300/585]\tloss 0.07343\n",
      "Train: [7][400/585]\tloss 0.07496\n",
      "Train: [7][500/585]\tloss 0.07456\n",
      "Test accuracy:  0.6691266912669127\n",
      "***********************************\n",
      "Train: [8][100/585]\tloss 0.04672\n",
      "Train: [8][200/585]\tloss 0.04886\n",
      "Train: [8][300/585]\tloss 0.04554\n",
      "Train: [8][400/585]\tloss 0.04530\n",
      "Train: [8][500/585]\tloss 0.04385\n",
      "Test accuracy:  0.6543665436654367\n",
      "***********************************\n",
      "Train: [9][100/585]\tloss 0.03433\n",
      "Train: [9][200/585]\tloss 0.02937\n",
      "Train: [9][300/585]\tloss 0.03211\n",
      "Train: [9][400/585]\tloss 0.03344\n",
      "Train: [9][500/585]\tloss 0.03272\n",
      "Test accuracy:  0.6789667896678967\n",
      "***********************************\n",
      "Train: [10][100/585]\tloss 0.02170\n",
      "Train: [10][200/585]\tloss 0.01906\n",
      "Train: [10][300/585]\tloss 0.01931\n",
      "Train: [10][400/585]\tloss 0.01870\n",
      "Train: [10][500/585]\tloss 0.01826\n",
      "Test accuracy:  0.6691266912669127\n",
      "***********************************\n",
      "Train: [11][100/585]\tloss 0.01436\n",
      "Train: [11][200/585]\tloss 0.01412\n",
      "Train: [11][300/585]\tloss 0.01347\n",
      "Train: [11][400/585]\tloss 0.01350\n",
      "Train: [11][500/585]\tloss 0.01435\n",
      "Test accuracy:  0.6642066420664207\n",
      "***********************************\n",
      "Train: [12][100/585]\tloss 0.01024\n",
      "Train: [12][200/585]\tloss 0.01149\n",
      "Train: [12][300/585]\tloss 0.01362\n",
      "Train: [12][400/585]\tloss 0.01321\n",
      "Train: [12][500/585]\tloss 0.01243\n",
      "Test accuracy:  0.6642066420664207\n",
      "***********************************\n",
      "Train: [13][100/585]\tloss 0.01053\n",
      "Train: [13][200/585]\tloss 0.01004\n",
      "Train: [13][300/585]\tloss 0.00981\n",
      "Train: [13][400/585]\tloss 0.00962\n",
      "Train: [13][500/585]\tloss 0.01094\n",
      "Test accuracy:  0.6715867158671587\n",
      "***********************************\n",
      "Train: [14][100/585]\tloss 0.00947\n",
      "Train: [14][200/585]\tloss 0.00966\n",
      "Train: [14][300/585]\tloss 0.00879\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c2ae51796ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = AverageMeter()\n",
    "    total_loss = 0\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     model.to(device)    \n",
    "    model.train()\n",
    "    for text, label in train_loader:\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True, max_length=512, truncation=True) for t in text]\n",
    "        padded_list = [e[:512] + [0] * (512-len(e[:512])) for e in encoded_list]\n",
    "        sample = torch.tensor(padded_list)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        label = torch.tensor(label)\n",
    "        outputs = model(sample=sample, isLabel=False)\n",
    "#         print(outputs.size())\n",
    "#         outputs = F.normalize(outputs, dim=2)\n",
    "#         print(label_tensor.size())\n",
    "#         print(outputs.size())\n",
    "        outputs = torch.matmul(outputs, label_tensor)\n",
    "#         print(outputs.size())\n",
    "#         outputs = torch.transpose(outputs, 1, 2)\n",
    "#         outputs = nn.AdaptiveMaxPool1d(1)(outputs)\n",
    "#         outputs = torch.squeeze(outputs)\n",
    "#         print(outputs.size())\n",
    "        \n",
    "        pred = torch.argmax(F.softmax(outputs), dim=1)\n",
    "        correct = pred.eq(label)\n",
    "        loss = criterion(outputs, label)\n",
    "        losses.update(loss.item(), BATCH_SIZE)\n",
    "#         print(loss)\n",
    "        \n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(label)\n",
    "        total_loss += loss.item()\n",
    "        total_count += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        if (total_count + 1) % 100 == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'\n",
    "                  'loss {loss.avg:.5f}'.format(\n",
    "                   epoch, total_count + 1, len(train_loader), loss=losses))   \n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    model_eval(test_df, label_tensor)\n",
    "#     label_tensor = get_label_tensor()\n",
    "#     model_eval(test_df, label_tensor)\n",
    "    print('***********************************')\n",
    "#     print(tloss)     \n",
    "model_eval(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
