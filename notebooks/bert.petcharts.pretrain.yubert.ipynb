{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rN2MWC4mrZJ"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMeoW8Sfm8WW"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('./gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67xO0EHHm-V7"
   },
   "outputs": [],
   "source": [
    "# cd /content/gdrive/My\\ Drive/DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqZmmgoVnI5S"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaTokenizerFast, RobertaTokenizer\n",
    "from transformers import RobertaForMaskedLM\n",
    "from modeling_yubert import YubertForMaskedLM, YubertLMHead\n",
    "\n",
    "pretrained_dir = './pretrained_local'\n",
    "# tokenizer_dir = './tokenizer'\n",
    "log_dir='logs'\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=32000,\n",
    "    max_position_embeddings=516,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    "#     hidden_size=768,\n",
    "#     num_attention_heads=12,\n",
    "#     intermediate_size=3072,\n",
    "    hidden_size=384,\n",
    "    num_attention_heads=6,\n",
    "    intermediate_size=1536,   \n",
    "    isjupyter=True,\n",
    "    seq_len=256,\n",
    "    med_seq_len=64\n",
    ")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(pretrained_dir, max_len=512)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(pretrained_dir, max_len=512)\n",
    "model = YubertForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.add_special_tokens({\"s1_token\":\"<s1>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.add_special_tokens('<s1')\n",
    "# tokenizer.add_special_tokens({cls_token2 :'<s2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 5, 3, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>', '<pad>', '<mask>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids({'<s1>': 1})\n",
    "tokenizer.convert_tokens_to_ids({'<s2>': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 18994, 306, 5651, 603, 1576, 227, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"너는 누구야 \")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 34, 89, 23, 36, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('<s1>')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s1>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '<pad>',\n",
       " AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2500, 9570, 1259, 1149, 2835, 18, 22284, 6948, 15695, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"안녕 반가워, hi my pet\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 18994, 306, 5651, 603, 1576, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"너는 누구야\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35750528\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print(model)\n",
    "# print(model)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezRFuiUonMaf"
   },
   "outputs": [],
   "source": [
    "# model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKyw-BVfnN1X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 21279, 18, 23607, 7575, 4027, 7187, 4114, 12515, 20, 1301, 8031, 3793, 5269, 2035, 6059, 3793, 8802, 4763, 1549, 3793, 1702, 13420, 6476, 4745, 1319, 14539, 15258, 7257, 1071, 5817, 26767, 3281, 4865, 31178, 3415, 3557, 3484, 285, 414, 15920, 4813, 2907, 6435, 12496, 4027, 19593, 11417, 3055, 3172, 1335, 436, 3104, 4912, 1335, 2018, 3746, 447, 4386, 5817, 11417, 4126, 2496, 4], [0, 1, 2, 558, 5106, 12511, 1216, 1503, 605, 542, 1223, 1458, 4406, 2153, 5154, 552, 1223, 4678, 964, 423, 285, 756, 6418, 19281, 123, 557, 1494, 1838, 3885, 28673, 6242, 8084, 10069, 1921, 2029, 3729, 3885, 14487, 5670, 5679, 1649, 602, 8808, 11946, 4366, 2507, 726, 1906, 919, 1119, 15282, 3359, 602, 4726, 8367, 2597, 4], [0, 1, 2, 7513, 930, 7656, 6978, 4634, 3312, 3850, 762, 1912, 7278, 11946, 4076, 20, 22226, 3842, 649, 945, 1804, 20, 996, 2362, 423, 14938, 10033, 996, 2362, 635, 20, 2369, 407, 490, 875, 4965, 22226, 2676, 1640, 17436, 2616, 1123, 20, 2086, 11661, 1220, 6126, 7108, 342, 649, 1804, 782, 491, 3526, 1502, 26330, 2869, 9380, 1586, 417, 3526, 5640, 9938, 3223, 2362, 3577, 3223, 12888, 1640, 855, 9947, 5846, 6778, 3260, 5723, 5437, 756, 20, 1531, 22823, 655, 2359, 1441, 7758, 1597, 20, 1766, 3292, 22817, 3608, 3526, 1502, 801, 2802, 974, 1347, 8055, 20, 22226, 3397, 1998, 2795, 8778, 1891, 12455, 861, 1253, 1477, 541, 762, 491, 1900, 1603, 8477, 2216, 618, 5723, 9691, 7000, 3042, 976, 423, 5742, 921, 20, 22226, 1093, 15674, 14353, 1194, 1586, 1186, 738, 2463, 5592, 1874, 11143, 747, 2138, 423, 851, 618, 515, 2454, 2953, 2475, 13740, 398, 7085, 605, 1223, 20, 3243, 605, 541, 692, 417, 855, 582, 1013, 2173, 11731, 762, 1912, 15938, 6611, 1213, 358, 4200, 12069, 871, 8609, 782, 491, 3606, 782, 2965, 5952, 23683, 2507, 726, 12369, 2906, 11644, 5622, 2244, 12687, 974, 448, 30414, 5622, 26794, 2325, 747, 986, 7333, 4846, 594, 855, 1535, 447, 1482, 3028, 7637, 2244, 15116, 3534, 2590, 16224, 9110, 4834, 10526, 8660, 2454, 2953, 1712, 3243, 5727, 605, 1795, 726, 11391, 1795, 557, 20, 8432, 6235, 1039, 14441, 20053, 2623, 4635, 1163, 1050, 961, 1691, 756, 29592, 1874, 8020, 15773, 6420, 557, 20, 891, 447, 2274, 1015, 2471, 1357, 822, 2157, 6978, 4634, 891, 12866, 891, 4], [0, 1, 2, 358, 1365, 940, 13090, 20, 1026, 940, 1246, 18, 1383, 20, 13551, 26435, 8843, 20, 941, 32, 6153, 467, 334, 2822, 22, 20, 25, 17092, 272, 1357, 822, 848, 20, 4]]\n",
      "CPU times: user 7min 50s, sys: 8.4 s, total: 7min 59s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "#     file_path=\"./files/pet_smallist.txt\",\n",
    "    file_path=\"./files/pet_0814.txt\",\n",
    "    block_size=256,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "LEARN_RATE = 0.00006\n",
    "MAX_WARMUP_STEPS = 30000\n",
    "SAVE_STEPS = 10000\n",
    "MAX_STEPS = 30000\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), lr=LEARN_RATE, betas=(0.9, 0.999), weight_decay=0.1\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=MAX_WARMUP_STEPS,\n",
    "    num_training_steps=len(dataset) * NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObEi4rCgnQ5K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/.local/lib/python3.6/site-packages/transformers/trainer.py:245: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead.\n",
      "  FutureWarning,\n",
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "# SEED = np.random.randint(0, 100000, size=None)\n",
    "SEED = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=log_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_gpu_train_batch_size=BATCH_SIZE,\n",
    "    max_steps=MAX_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=5,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6007188289b44c1a38165b0c42484ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ead2a868b74512b289ae107ed9c590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=83234.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.418813261032104, 'learning_rate': 1e-06, 'epoch': 0.006007160535358147, 'step': 500}\n",
      "{'loss': 10.115291399002075, 'learning_rate': 2e-06, 'epoch': 0.012014321070716294, 'step': 1000}\n",
      "{'loss': 9.6983158493042, 'learning_rate': 3e-06, 'epoch': 0.01802148160607444, 'step': 1500}\n",
      "{'loss': 9.353532850265504, 'learning_rate': 4e-06, 'epoch': 0.024028642141432587, 'step': 2000}\n",
      "{'loss': 9.003611511230469, 'learning_rate': 4.9999999999999996e-06, 'epoch': 0.030035802676790735, 'step': 2500}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(pretrained_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(1,100) :\n",
    "    print('************************************************************', num)\n",
    "    LRATE = LEARN_RATE/((num/10)+1)\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(), lr=LRATE, betas=(0.9, 0.999), weight_decay=0.1\n",
    "    )\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=MAX_WARMUP_STEPS,\n",
    "        num_training_steps=len(dataset) * NUM_EPOCHS,\n",
    "    )\n",
    "\n",
    "    SEED = np.random.randint(0, 100000, size=None)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=log_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_gpu_train_batch_size=BATCH_SIZE,\n",
    "        max_steps=MAX_STEPS,\n",
    "        save_steps=SAVE_STEPS,\n",
    "        save_total_limit=5,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset,\n",
    "        prediction_loss_only=True,\n",
    "        optimizers=(optimizer, scheduler),\n",
    "    )\n",
    "\n",
    "#     %%time\n",
    "    trainer.train()\n",
    "\n",
    "trainer.save_model(pretrained_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(pretrained_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO6VXFF9IYkIBDVgYG4YotR",
   "collapsed_sections": [],
   "name": "bert.petcharts.pretrained.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
